nohup python3 train.py \
--data_dir ./dataset/docred \
--transformer_type bert \
--model_name_or_path bert-base-cased \
--train_file ./cil/train_annotated_pretrain_241.json \
--dev_file ./cil/dev_pretrain_241.json \
--test_file ./test.json \
--train_batch_size 4 \
--test_batch_size 8 \
--gradient_accumulation_steps 1 \
--num_labels 4 \
--learning_rate 5e-5 \
--max_grad_norm 1.0 \
--warmup_ratio 0.06 \
--num_train_epochs 30.0 \
--seed 66 \
--num_class 96 \
--num_incr_head 2 \
--rel_mode _pretrain_241 \
--evaluation_steps -1 \
--save_path chkpt/EIDER_bert_eider__exp_pretrain_241__best_test.pt \
--ablation eider \
--name _exp_pretrain_241_ \
--feature_path saved_features \
--coref_method hoi \
--eval_mode dev_only \
--evi_eval_mode none \
--ensemble_mode 2 \
--ensemble_ablation evi_rule \
--evi_pred_file evi_results_eider_bert-base-cased.pkl \
--load_path chkpt/EIDER_bert_eider__exp_pretrain_241__best.pt \
> output__exp_pretrain_241__test.log 2>&1